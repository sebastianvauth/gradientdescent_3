<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Gradient Descent Algorithm in Detail</title>
    <style>
        body {
            font-family: Arial, sans-serif;
            max-width: 800px;
            margin: 0 auto;
            padding: 20px;
            background-color: #ffffff;
            font-size: 150%;
        }
        section {
            margin-bottom: 20px;
            padding: 20px;
            background-color: #ffffff;
            display: none;
            opacity: 0;
            transition: opacity 0.5s ease-in;
        }
        h1, h2, h3, h4 {
            color: #333;
            margin-top: 20px;
        }
        p, li {
            line-height: 1.6;
            color: #444;
            margin-bottom: 20px;
        }
        ul {
            padding-left: 20px;
        }
        .image-placeholder, .interactive-placeholder, .continue-button, .vocab-section, .why-it-matters, .test-your-knowledge, .faq-section, .stop-and-think {
            text-align: left;
        }
        .image-placeholder img, .interactive-placeholder img {
            max-width: 100%;
            height: auto;
            border-radius: 5px;
        }
        .vocab-section, .why-it-matters, .test-your-knowledge, .faq-section, .stop-and-think {
            padding: 20px;
            border-radius: 8px;
            margin-top: 20px;
        }
        .vocab-section {
            background-color: #f0f8ff;
        }
        .vocab-section h3 {
            color: #1e90ff;
            font-size: 0.75em;
            margin-bottom: 5px;
            margin-top: 5px;
        }
        .vocab-section h4 {
            color: #000;
            font-size: 0.9em;
            margin-top: 10px;
            margin-bottom: 8px;
        }
        .vocab-term {
            font-weight: bold;
            color: #1e90ff;
        }
        .why-it-matters {
            background-color: #ffe6f0;
        }
        .why-it-matters h3 {
            color: #d81b60;
            font-size: 0.75em;
            margin-bottom: 5px;
            margin-top: 5px;
        }
        .stop-and-think {
            background-color: #e6e6ff;
        }
        .stop-and-think h3 {
            color: #4b0082;
            font-size: 0.75em;
            margin-bottom: 5px;
            margin-top: 5px;
        }
        .continue-button {
            display: inline-block;
            padding: 10px 20px;
            margin-top: 15px;
            color: #ffffff;
            background-color: #007bff;
            border-radius: 5px;
            text-decoration: none;
            cursor: pointer;
        }
        .reveal-button {
            display: inline-block;
            padding: 10px 20px;
            margin-top: 15px;
            color: #ffffff;
            background-color: #4b0082;
            border-radius: 5px;
            text-decoration: none;
            cursor: pointer;
        }
        .test-your-knowledge {
            background-color: #e6ffe6;
        }
        .test-your-knowledge h3 {
            color: #28a745;
            font-size: 0.75em;
            margin-bottom: 5px;
            margin-top: 5px;
        }
        .test-your-knowledge h4 {
            color: #000;
            font-size: 0.9em;
            margin-top: 10px;
            margin-bottom: 8px;
        }
        .test-your-knowledge p {
            margin-bottom: 15px;
        }
        .check-button {
            display: inline-block;
            padding: 10px 20px;
            margin-top: 15px;
            color: #ffffff;
            background-color: #28a745;
            border-radius: 5px;
            text-decoration: none;
            cursor: pointer;
            border: none;
            font-size: 1em;
        }
        .faq-section {
            background-color: #fffbea;
        }
        .faq-section h3 {
            color: #ffcc00;
            font-size: 0.75em;
            margin-bottom: 5px;
            margin-top: 5px;
        }
        .faq-section h4 {
            color: #000;
            font-size: 0.9em;
            margin-top: 10px;
            margin-bottom: 8px;
        }
    </style>
    <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
</head>
<body>
    <section id="section1">
        <h1>Gradient Descent Algorithm in Detail</h1>
        <div class="image-placeholder">
            <img src="/placeholder.svg?height=300&width=600" alt="Image showing a detailed blueprint or schematic of an algorithm, symbolizing the detailed breakdown of the Gradient Descent process.">
        </div>
        <p>Welcome back, optimizer! ðŸ‘‹ We've learned about the core idea of Gradient Descent and how to calculate cost functions and gradients. Now, it's time to assemble all the pieces and understand the <strong>complete Gradient Descent Algorithm</strong> step-by-step. Think of this lesson as getting the detailed instructions to build and operate our 'downhill hiking machine'. Let's get algorithmic!</p>
        <div class="continue-button" onclick="showNextSection(2)">Continue</div>
    </section>

    <section id="section2">
        <h2>Algorithm Setup: Initialization</h2>
        <p>Before we start the iterative process of Gradient Descent, we need to set up a few things. This is like preparing our hiking gear before hitting the trail.</p>
        <p>First, we need to choose our <strong>hyperparameters</strong>. Remember, hyperparameters are settings that we set <em>before</em> training, and they control how the algorithm learns. For Gradient Descent, the key hyperparameters are:</p>
        <ul>
            <li><strong>Learning Rate ($$\alpha$$)</strong>: We've talked about this before! It controls the step size in each iteration. Think of it as deciding how quickly you want to descend the hill. A good learning rate is crucial â€“ too large, and we might overshoot the minimum; too small, and it might take forever to converge.</li>
        </ul>
        <div class="image-placeholder">
            <img src="/placeholder.svg?height=300&width=600" alt="Image depicting three scenarios of learning rates: (1) a hiker taking large, overshooting steps, (2) a hiker taking very small, slow steps, (3) a hiker taking moderately sized, efficient steps down a hill.">
        </div>
        <ul>
            <li><strong>Maximum Number of Iterations (N)</strong>: We need to set a limit on how many iterations Gradient Descent will run. This prevents the algorithm from running indefinitely if it's not converging well or if we just want to limit the training time. It's like setting a time limit for our hike.</li>
            <li><strong>Convergence Threshold ($$\epsilon$$)</strong>: This is a small positive value that determines when we consider the algorithm to have 'converged'. We stop iterating when the magnitude of the gradient becomes smaller than this threshold, indicating we're close to a minimum. It's like deciding how close to the bottom of the valley is 'close enough'.</li>
        </ul>
        <p>Next, we need to <strong>initialize our parameters</strong> $$\beta$$. We need a starting point for our 'hike'. Common choices for initialization are:</p>
        <ul>
            <li><strong>Random Initialization</strong>: We can initialize the parameters with small random values. This is often used for more complex models to break symmetry and allow different parts of the model to learn different things.</li>
            <li><strong>Initialization to Zeros</strong>: For simpler models like linear regression, we can often just initialize all parameters to zero. This can work well, especially if the features are reasonably scaled.</li>
        </ul>
        <p>So, to summarize the initialization step, we set our hyperparameters ($$\alpha$$, $$N$$, $$\epsilon$$) and choose an initial value for our parameters $$\beta_{start}$$. We're now ready to start the iterative process!</p>
        <div class="vocab-section">
            <h3>Build Your Vocab</h3>
            <h4 class="vocab-term">Hyperparameters</h4>
            <p>Parameters of a learning algorithm that are set <em>before</em> training and control the learning process itself. Examples in Gradient Descent are learning rate, maximum iterations, and convergence threshold.</p>
        </div>
        <p>With our gear ready and starting point chosen, let's begin our descent!</p>
        <div class="continue-button" onclick="showNextSection(3)">Continue</div>
    </section>

    <section id="section3">
        <h2>The Iterative Descent: Step-by-Step</h2>
        <p>This is the heart of the Gradient Descent Algorithm! We repeat these steps until we meet a termination condition.</p>
        <p>Inside the iteration loop, we perform the following steps:</p>
        <ol>
            <li><strong>Step 1: Calculate the Gradient</strong>: We calculate the gradient of the cost function $$\nabla_{\beta}C(\beta)$$ at the current parameter values $$\beta$$. Remember from Lesson 2, this gradient tells us the direction of steepest ascent (uphill).</li>
            <li><strong>Step 2: Update Parameters</strong>: We update the parameters by taking a step in the <em>opposite</em> direction of the gradient (downhill), scaled by the learning rate $$\alpha$$:
                <p>\[\beta_{new} = \beta_{old} - \alpha \nabla_{\beta}C(\beta_{old})\]</p>
            </li>
            <li><strong>Step 3: Check for Convergence</strong>: After updating the parameters, we need to check if we should stop. We typically check two conditions:
                <ul>
                    <li><strong>Condition 1: Gradient Magnitude Check</strong>: We calculate the magnitude (or norm) of the gradient, $$||\nabla_{\beta}C(\beta)||_2$$. If this magnitude is smaller than our convergence threshold $$\epsilon$$, it means the gradient is very close to zero, and we're likely near a minimum. In this case, we stop.</li>
                    <li><strong>Condition 2: Maximum Iterations Check</strong>: We check if we have reached the maximum number of iterations $$N$$. If we have, we stop, even if the gradient magnitude is still above the threshold. This is a safeguard against very slow convergence or non-convergence. It's our 'time limit' for the hike.</li>
                </ul>
            </li>
        </ol>
        <p>We repeat steps 1-3 until <em>at least one</em> of these termination conditions is met. Once we stop, the current parameter values $$\beta$$ are considered our 'learned' parameters, $$\beta_{learned}$$, which hopefully minimize the cost function (or get us very close to the minimum).</p>
        <div class="image-placeholder">
            <img src="/placeholder.svg?height=400&width=600" alt="Flowchart diagram of the Gradient Descent Algorithm. Start with 'Initialization (Î±, N, Îµ, Î²_start)'. Loop: 'Calculate Gradient âˆ‡Î²C(Î²)', 'Update Î² = Î² - Î±âˆ‡Î²C(Î²)', 'Check Convergence: ||âˆ‡C(Î²)||â‚‚ < Îµ OR Iterations >= N?'. If Yes, 'Stop & Output Î²_learned'. If No, loop back to 'Calculate Gradient'. Use clear arrows and boxes to represent the flow.">
        </div>
        <div class="vocab-section">
            <h3>Build Your Vocab</h3>
            <h4 class="vocab-term">Convergence</h4>
            <p>In Gradient Descent, convergence refers to the algorithm reaching a point where the cost function stops decreasing significantly and the parameters stabilize, indicating a minimum has been found (or closely approached).</p>
        </div>
        <p>These iterative steps are how Gradient Descent systematically finds its way to the minimum!</p>
        <div class="continue-button" onclick="showNextSection(4)">Continue</div>
    </section>

    <section id="section4">
        <h2>Putting It in Motion</h2>
        <p>Let's visualize how Gradient Descent works with an example (conceptual, not numerical here). Imagine our cost function again as a bowl-shaped curve.</p>
        <div class="interactive-placeholder">
            <img src="/placeholder.svg?height=400&width=600" alt="Interactive 2D graph of a U-shaped cost function curve. Controls: Sliders to adjust Learning Rate (Î±), Max Iterations (N), Convergence Threshold (Îµ). Button: 'Run Gradient Descent'. Animation: Start from a fixed Î²_start. On button click, animate step-by-step Gradient Descent iterations on the curve. Show each step as an arrow moving downhill. Display the number of iterations taken and the final Î²_learned value achieved. Allow users to change hyperparameters and rerun to observe the effects on convergence speed and path.">
        </div>
        <p>Try adjusting the learning rate and see how it affects the speed and stability of the descent. What happens if you make the learning rate too large? Too small?</p>
        <div class="continue-button" onclick="showNextSection(5)">Continue</div>
    </section>

    <section id="section5">
        <h2>Why Both Termination Conditions?</h2>
        <div class="stop-and-think">
            <h3>Stop and Think</h3>
            <h4>Why do we need <em>both</em> the gradient magnitude threshold and the maximum iterations as termination conditions? Why isn't one of them enough?</h4>
            <button class="reveal-button" onclick="revealAnswer('stop-and-think-1')">Reveal</button>
            <p id="stop-and-think-1" style="display: none;">The gradient magnitude threshold is ideal for convergence, but in practice, cost functions can have flat regions or very slow descent, making the gradient magnitude decrease very slowly. Without a maximum iteration limit, the algorithm might run for a very long time without significant progress. The maximum iteration limit acts as a safeguard against such situations and ensures the algorithm terminates in a reasonable time, even if perfect convergence isn't achieved.</p>
        </div>
        <div class="continue-button" onclick="showNextSection(6)">Continue</div>
    </section>

    <section id="section6">
        <h2>Frequently Asked Questions</h2>
        <div class="faq-section">
            <h3>Frequently Asked Questions</h3>
            <h4>How do I choose the 'right' learning rate, maximum iterations, and convergence threshold?</h4>
            <p>Choosing these hyperparameters often involves experimentation and tuning. There's no one-size-fits-all answer. The 'right' values depend on the specific problem, dataset, and cost function. Techniques like cross-validation and learning rate schedules are often used to find good hyperparameter values. We'll touch upon these in later, more advanced courses!</p>
        </div>
        <div class="continue-button" onclick="showNextSection(7)">Continue</div>
    </section>

    <section id="section7">
        <h2>Test Your Knowledge</h2>
        <div class="test-your-knowledge">
            <h3>Test Your Knowledge</h3>
            <h4>Which step in the Gradient Descent algorithm directly uses the learning rate ($$\alpha$$)?</h4>
            <div id="quiz-options">
                <p><input type="radio" name="quiz" value="0"> Calculating the Gradient $$\nabla_{\beta}C(\beta)$$</p>
                <p><input type="radio" name="quiz" value="1"> Updating Parameters $$\beta_{new} = \beta_{old} - \alpha \nabla_{\beta}C(\beta_{old})$$</p>
                <p><input type="radio" name="quiz" value="2"> Checking for Convergence $$||\nabla_{\beta}C(\beta)||_2 < \epsilon$$</p>
                <p><input type="radio" name="quiz" value="3"> Initialization of Parameters $$\beta_{start}$$</p>
            </div>
            <button class="check-button" onclick="checkAnswer()">Check Answer</button>
            <p id="quiz-result" style="display: none;"></p>
        </div>
        <div class="continue-button" onclick="showNextSection(8)">Continue</div>
    </section>

    <section id="section8">
        <h2>Ready for Implementation!</h2>
        <p>Fantastic! ðŸš€ You've now mastered the detailed steps of the Gradient Descent Algorithm. You understand how it's initialized, how it iteratively updates parameters using gradients and the learning rate, and how it knows when to stop. You're well-equipped to start implementing Gradient Descent yourself! In our next lessons, we'll explore variations of Gradient Descent and delve into some of its challenges and nuances. Keep up the great work!</p>
    </section>

    <script>
        // Show the first section initially
        document.getElementById("section1").style.display = "block";
        document.getElementById("section1").style.opacity = "1";

        function showNextSection(nextSectionId) {
            const currentButton = event.target;
            const nextSection = document.getElementById("section" + nextSectionId);
            
            currentButton.style.display = "none";
            
            nextSection.style.display = "block";
            setTimeout(() => {
                nextSection.style.opacity = "1";
            }, 10);

            setTimeout(() => {
                nextSection.scrollIntoView({ behavior: 'smooth', block: 'start' });
            }, 500);
        }

        function revealAnswer(id) {
            const revealText = document.getElementById(id);
            const revealButton = event.target;
            
            revealText.style.display = "block";
            revealButton.style.display = "none";
        }

        function checkAnswer() {
            const selectedOption = document.querySelector('input[name="quiz"]:checked');
            const resultElement = document.getElementById("quiz-result");
            
            if (selectedOption) {
                const answer = parseInt(selectedOption.value);
                if (answer === 1) {
                    resultElement.textContent = "Correct! The learning rate Î± is multiplied by the gradient in the parameter update step to control the step size.";
                    resultElement.style.color = "green";
                } else {
                    resultElement.textContent = "Incorrect. The learning rate Î± is used in the parameter update step: Î²_new = Î²_old - Î±âˆ‡_Î²C(Î²_old)";
                    resultElement.style.color = "red";
                }
                resultElement.style.display = "block";
            } else {
                alert("Please select an answer before checking.");
            }
        }
    </script>
</body>
</html>
